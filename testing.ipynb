{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anirban\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 20 variables whereas the saved optimizer has 38 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model=load_model('cat_dog_classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('image3.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize((256, 256))  # Resize to match model input size\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array /= 255.0  # Normalize\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00682133]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718ms/step\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread('cat image.jpeg')\n",
    "\n",
    "    # Preprocess the image using OpenCV\n",
    "test_img=cv2.resize(img,(256,256))  # Resize to match model input size\n",
    "\n",
    "test_input=test_img.reshape((1,256,256,3))\n",
    "    # Make prediction\n",
    "prediction = model.predict(test_input)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a cat\n"
     ]
    }
   ],
   "source": [
    "if prediction[0][0]==0.0 :\n",
    "        print(\"this is a cat\")\n",
    "elif prediction[0][0]==1.0:\n",
    "        print(\"this is a dog\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Anirban\\AppData\\Local\\Temp\\tmpzpk1ra_b\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Anirban\\AppData\\Local\\Temp\\tmpzpk1ra_b\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Anirban\\AppData\\Local\\Temp\\tmpzpk1ra_b'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name='input_layer_2')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1844026683280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026684240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026684624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026684816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026676176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026682128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026685584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026686736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026686352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026687120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026685968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844026686928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844027326928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1844027328080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843939520592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843939522128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843939519632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843939521936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843939520976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843920586320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843920587664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843920592656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843878282832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1843878289552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the original model\n",
    "model = tf.keras.models.load_model('cat_dog_classifier.keras')\n",
    "\n",
    "# Convert to TensorFlow Lite with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('cat_dog_classifier_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
